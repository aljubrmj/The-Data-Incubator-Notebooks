{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Visualization\n",
    "<!-- requirement: small_data/goog.json -->\n",
    "<!-- requirement: small_data/temperatures.csv -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One purpose of visualization is to help the analyst understand and model the data at hand. Exploratory visualization prioritizes speed over style, in contrast to explanatory visualization.\n",
    "\n",
    "A few popular python packages are presented below, along with some boilerplate code and external references. \n",
    "\n",
    "The rest of the notebook focuses on interactive data exploration inside a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python visualization tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* matplotlib (a [thorough rundown](http://www.randalolson.com/2014/06/28/how-to-make-beautiful-data-visualizations-in-python-with-matplotlib/) of its potential)\n",
    "* [pandas](http://pandas.pydata.org/pandas-docs/stable/visualization.html) has its own useful plotting interface around matplotlib\n",
    "* [Seaborn](https://github.com/mwaskom/seaborn) (focuses on statistics, easier to customize than matplotlib)\n",
    "* [Altair](https://altair-viz.github.io/) (focus on interactivity, browser delivery)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domains for exploratory and explanatory visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to techniques using D3, which tend to focus on polished, *explanatory* visualizations for the end-user, Jupyter notebooks tend to be more useful for *exploration*. This is the time when running code interactively is useful because you're interested in the effect of changing a few lines of code without rerunning the entire script. We already discussed the rationale behind including visualization as part of your data exploration, and interactivity is a powerful tool to accomplish that objective, whether it's just you, or your team huddled around your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing a distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mean\n",
    "* Median\n",
    "* Variance\n",
    "* Standard Deviation\n",
    "\n",
    "Often statistical parameters provide important insight into the data - and can reveal information that is not visually obvious. However, it's important to consider their limitations as well and think about what is gained by visual exploration.\n",
    "\n",
    "Outliers are a good place to start - visually they are easy to spot but they can have deceptive influence on statistical metrics. Consider [Anscombe's Quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet), a set of four distributions with nearly identical aggregate properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq = sns.load_dataset(\"anscombe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *x* and *y* components of each set have similar means and standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in ('I', 'II', 'III', 'IV'):\n",
    "    print('Dataset ' + ds)\n",
    "    print(str(aq[aq['dataset'] == ds].describe())+ \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each data set, the *x* and *y* components have nearly identical correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in ('I', 'II', 'III', 'IV'):\n",
    "    print('Dataset {}: {}'.format(ds, aq[aq['dataset'] == ds].corr().loc['x', 'y']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So do the data sets represent the same relation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"x\", y=\"y\", col=\"dataset\", hue=\"dataset\", data=aq,\n",
    "           col_wrap=2, ci=None, palette=\"muted\", height=4,\n",
    "           scatter_kws={\"s\": 50, \"alpha\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question*: When can situation 4 arise in real life? What can be done to identify this kind of situation in the feature space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset(\"tips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms are indispensable tools for visualizing distributions in your data. When working with DataFrames, `pandas` makes it easy to quickly get histograms of your features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tips.shape) # columns, rows\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_hist = tips.hist()    #pandas hist() function. tips is a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these will work\n",
    "# tips_fig.savefig('tiphist.png')\n",
    "# tips_fig.savefig('tiphist.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on kernel density estimation, check out these blog posts:\n",
    "* [Michael Lerner's motivation of KDE based on histograms](http://www.mglerner.com/blog/?p=28)\n",
    "* [A comparison of KDE methods in Python](https://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box plots and Violin Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='total_bill', data=tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"day\", y=\"total_bill\", hue=\"smoker\", data=tips, palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see more examples in the API: \n",
    "http://seaborn.pydata.org/generated/seaborn.violinplot.html#seaborn.violinplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships between variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.plotting.scatter_matrix(tips, alpha=0.2, figsize=(6, 6), diagonal='kde')\n",
    "# available in seaborn as pairplot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common metric is [Pearson's](https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient) correlation coefficient (covariance normalized by the product of the standard deviations), which ranges between 1 being total positive correlation and -1 being total negative correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='total_bill', y='tip', data=tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question*: Imagine you're trying to do some feature selection using Pearson's coefficient. What are two situations where this metric can be misleading?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indirect Influence / constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- e.g. speed is highly correlated with accidents only if driving on the highway\n",
    "- This mostly boils down to intelligently looking at subsets of the data, edge cases, etc.\n",
    "- Leave one out for predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tips['tip'].mean())\n",
    "print(tips[tips['size'] > 1]['tip'].mean())\n",
    "print(tips[tips['size'] == 1]['tip'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question*: How meaningful is the above? What else do we need to consider?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='total_bill', y='tip', hue='time', data=tips, palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-obvious patterns in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: here, we focus on plotting this kind data. Details on time-series analysis are provided in module 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot, lag_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get temperature data\n",
    "temps_df = pd.read_csv(\"small_data/temperatures.csv\", \n",
    "                       index_col=0,\n",
    "                       names=[\"Temperature\"],\n",
    "                       parse_dates=True,\n",
    "                       date_parser=lambda u: pd.datetime.strptime(u, \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# get GOOG data\n",
    "import simplejson as json\n",
    "\n",
    "with open('small_data/goog.json') as raw_f:\n",
    "    raw_data = raw_f.read()\n",
    "    json_data = json.loads(raw_data)\n",
    "\n",
    "json_data = json.loads(raw_data)\n",
    "goog_df = pd.DataFrame(json_data['data'], columns=json_data['column_names'])\n",
    "\n",
    "goog_open = goog_df['Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(goog_df.columns)\n",
    "goog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goog_df['Open'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autocorrelation is near 1 for short lags\n",
    "autocorrelation_plot(goog_open)\n",
    "matplotlib.pyplot.xlabel('Lag (days)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_df[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonality is apparent in the temperature data\n",
    "# this represents 13 years of temperatures, note 13 oscillations\n",
    "autocorrelation_plot(temps_df)\n",
    "matplotlib.pyplot.xlabel('Lag (hours)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using FFT to tease out trends in a time series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background notes on Fourier Analysis:**\n",
    "Any periodic signal can be represented as the sum of a number of sine waves with varying amplitude, phase, and frequency.\n",
    "\n",
    "A time series can be converted into its frequency components with the mathematical tool known as the Fourier transform. As we are dealing with sampled data, we must use the discrete version. The common algorithm for computing discrete transforms in the fast Fourier transform, usually abbreviated FFT.\n",
    "\n",
    "The **output of a FFT can be thought of as a representation of all the frequency components of your data**. In some sense it is a histogram with each “frequency bin” corresponding to a particular frequency in your signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a simple example to illustrate FFT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data\n",
    "N = 600\n",
    "T = 1.0 / 800.0\n",
    "\n",
    "x = np.linspace(0.0, N*T, N)\n",
    "y = np.sin(50.0 * 2.0 * np.pi * x) + 0.5*np.sin(80.0 * 2.0 * np.pi * x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title(\"The data\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT of the data\n",
    "# (usually, you subtract the mean before performing FFT...)\n",
    "yf = scipy.fftpack.fft(y)\n",
    "xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xf, 2.0/N * np.abs(yf[:N//2]))\n",
    "plt.title(\"FFT of the data\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In words, explain how the FFT plot relates to the plot of the data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactivity in visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is possible to include additional axes of data using color, thickness, texture, etc., it can be beneficial to use interactivity for this purpose.\n",
    "* Gives the end user control, gets them engaged with the data.\n",
    "* Allows for the base graph to be less cluttered and send a clearer message.\n",
    "* \"Feels\" impressive. Interactive graphs make you feel like there's a vast amount of data which you're tapping into.\n",
    "\n",
    "Most web-deployed interactive plots (or dashboards, as people like to call them) run on D3. You give these tools a large data source server-side, and the JavaScript can rapidly render the desired slice of the data. For polished tools, look at Bokeh server, `Pyxley`, or `highcharts`. \n",
    "\n",
    "Even in exploratory visualization, interactivity can enable you (or your team!) to more quickly identify important characteristics of your data and ascertain relationships between features. `Altair` is an easy-to-use Python package that enables a broad range of interactivity in just a few lines of code. It is an ideal candidate for interactivity in exploratory visualizations and still powerful enough for more polished visualizations as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by making a simple scatter plot -- we'll add interactivity in the next step.\n",
    "\n",
    "Once again we'll use the `tips` DataFrame. We'll tell Altair to make **point**  marks, and give it an **encoding** specifying which feature should be shown in each axis, as well as which feature should control the color of the points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Chart()` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary class used in Altair is `Chart()`, upon which marks, encodings, and interactivity can be applied.\n",
    "\n",
    "Note that in Altair, calling a method on a `Chart` object returns another `Chart` object, meaning that methods can be \"chained\" together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter=alt.Chart(tips).mark_point().encode(\n",
    "    x='total_bill',\n",
    "    y='tip',\n",
    "    color='smoker'\n",
    ")\n",
    "\n",
    "scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, creating a chart in Altair involves the following steps:\n",
    "   * specify a data source (a pandas DataFrame)\n",
    "   * choose a type of mark (e.g. lines, points)\n",
    "   * specify an *encoding* (set axes, visual cues)\n",
    "   * define interactivity\n",
    "   \n",
    "   \n",
    "We've done the first three steps already. We can add some basic pan/zoom interactivity to Altair by adding `.interactive()` to our chart. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altair really begins to shine when we combine multiple, interactive views of our data. Let's add a histogram for the `size` column, and add a `selection` to it so that we can get conditional scatter plots based on the value of size.\n",
    "\n",
    "We're using a `selection_multi()` instance in Altair, so we can select multiple values in the histogram with `Shift+Click`. We initialize the selection with the argument `encodings=['x']` , which tells Altair that the selections should refer only to the `x` value of the selected entries.\n",
    "\n",
    "* Multiple charts can be displayed using `chart1 & chart2` (vertical) or `chart1 | chart2` (horizontal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_selector = alt.selection_multi(encodings=['x'])\n",
    "\n",
    "\n",
    "scatter = alt.Chart(tips, width=500).mark_point().encode(\n",
    "    x=\"total_bill\",\n",
    "    y=\"tip\",\n",
    "    #selected sizes are colored according to the \"smoker\" column, others are rendered in white\n",
    "    color = alt.condition( size_selector , \"smoker\", alt.value(\"white\"))\n",
    ")\n",
    "    \n",
    "\n",
    "size_hist = alt.Chart(tips, width=500, height=200).mark_bar().encode(\n",
    "    x = \"size:N\",\n",
    "    y = \"count()\",\n",
    "    color = alt.condition(size_selector, alt.value(\"blue\"), alt.value(\"lightgray\"))\n",
    ").add_selection(size_selector)\n",
    "\n",
    "scatter & size_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine multiple selections and bindings to get even more powerful interactions!\n",
    "\n",
    "Below, we've added selection tools to the scatter plot as well, and the size histogram is altered to only consider points lying in the selection.\n",
    "\n",
    " * Note the use of `transform_filter` in the specification of `size_hist`, which tells Altair to only include points in the selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_selector = alt.selection_multi(encodings=['x'], empty='all')\n",
    "scatter_selector = alt.selection(type='interval', encodings=['x','y'], empty='all')\n",
    "\n",
    "\n",
    "scatter = alt.Chart(tips, width = 500).mark_point().encode(\n",
    "    x = \"total_bill\",\n",
    "    y = \"tip\",\n",
    "    color = alt.condition(size_selector | scatter_selector, \"smoker\", alt.value(\"white\"))\n",
    ").add_selection(scatter_selector)\n",
    "    \n",
    "size_hist = alt.Chart(tips, width=500, height=200).mark_bar().encode(\n",
    "    x = \"size:N\",\n",
    "    y = \"count()\",\n",
    "    color = alt.condition(size_selector , alt.value(\"blue\"), alt.value(\"lightgray\"))\n",
    ").transform_filter(\n",
    "    scatter_selector\n",
    ").add_selection(size_selector)\n",
    "\n",
    "scatter & size_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given stock (Google, in this example), let's say we want to visualize changes in opening price, closing price, daily high/low prices, and trade volume over time. We can use Altair to create an interactive line plot that allows us to select which feature to plot as the y-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ujson as json\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('small_data/goog.json') as raw_f:\n",
    "    raw_data = raw_f.read()\n",
    "    json_data = json.loads(raw_data)\n",
    "    \n",
    "df = pd.DataFrame(json_data['data'], columns=json_data['column_names'])\n",
    "df.set_index(pd.DatetimeIndex(df['Date']), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at this DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A basic line chart in Altair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a basic line chart, which will serve as a template to build our interactive chart.\n",
    "* Note the use of `mark_line()` instead of `mark_point()`. \n",
    "* Altair's logical separation of **marks** and **encodings** makes it very fast to switch between multiple types of charts. What happens if we add `.mark_point()` to the bottom line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "base = alt.Chart(df).mark_line().encode(\n",
    "    alt.X('Date:T'),\n",
    "    alt.Y('Close')\n",
    ")\n",
    "base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `:T` next to the word Date above. This tells Altair what kind of data the `Date` column contains. Altair uses the following specifications:\n",
    "  * `:N` Nominal (Categorical)\n",
    "  * `:O` Ordinal\n",
    "  * `:Q` Quantitative (Interval, Ratio)\n",
    "  * `:T` Time (Special formatting for dates and times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactively select a y-variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend the functionality of this chart further by modifying it for some interactivity. Let's add a drop down menu that allows for selecting a column to plot as a y-value. \n",
    "\n",
    "To do so, we'll first have to change the shape of our DataFrame from its current *wide* format to a more Altair-friendly *long* format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df.melt(id_vars=\"Date\", value_vars=['Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "df_long.sample(10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify a **binding**, which will set the column values (or in this case, values in the variable column) and a **selection**, which will be added to the chart to enable the interactivity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(df_long).mark_line().encode(\n",
    "    alt.X('Date:T'),\n",
    "    alt.Y('value', title=\" \")\n",
    ").properties(\n",
    "    height=240,\n",
    "    width = 600\n",
    ")\n",
    "\n",
    "\n",
    "# A dropdown filter\n",
    "columns=['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "column_dropdown = alt.binding_select(options=columns)\n",
    "column_select = alt.selection_single(\n",
    "    fields=['variable'],\n",
    "    on='doubleclick',\n",
    "    clear=False, \n",
    "    bind=column_dropdown, \n",
    "    name=\"y\",\n",
    "    init={'variable': \"Close\"}\n",
    ")\n",
    "\n",
    "\n",
    "filter_columns = base.add_selection(\n",
    "    column_select\n",
    ").transform_filter(\n",
    "    column_select\n",
    ")\n",
    "\n",
    "filter_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a date range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, it looks like both price and volume see a major uptick around July/August. What if we want to \"zoom in\" on those days interactively?\n",
    "\n",
    "We've seen how Altair enables a default pan/zoom interaction by simply calling the `.interactive()` method on a chart. Alternatively, let's say we want to specify a date range by selecting a time window on the entire graph, and obtain a view of just that range. Altair also makes this easy compared to other plotting packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new selection object.\n",
    "brush = alt.selection(type='interval', encodings=['x'], clear=False)\n",
    "\n",
    "\n",
    "\n",
    "#Link the domain selected by brush to the X range of the chart.\n",
    "base = alt.Chart(df_long, width=400, height=400).mark_line().encode(\n",
    "    alt.X('Date:T', scale=alt.Scale(domain=brush)),\n",
    "    alt.Y('value', title=\" \")\n",
    ")\n",
    "\n",
    "columns=['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "# A dropdown filter\n",
    "column_dropdown = alt.binding_select(options=columns)\n",
    "column_select = alt.selection_single(\n",
    "    fields=['variable'],\n",
    "    on='doubleclick',\n",
    "    clear=False, \n",
    "    bind=column_dropdown, \n",
    "    name=\"y_value\",\n",
    "    init={'variable': \"Close\"}\n",
    ")\n",
    "\n",
    "\n",
    "#Specify the top chart as a modification of the base chart\n",
    "filter_columns = base.add_selection(\n",
    "    column_select\n",
    ").transform_filter(\n",
    "    column_select\n",
    ").properties(\n",
    "    height=240,\n",
    "    width = 600\n",
    ")\n",
    "\n",
    "\n",
    "#Specify the lower chart as a modification of the base chart\n",
    "lower = filter_columns.add_selection(\n",
    "    column_select\n",
    ").transform_filter(\n",
    "    column_select\n",
    ").properties(\n",
    "    height=60,\n",
    "    width = 600\n",
    ").add_selection(brush)\n",
    "\n",
    "\n",
    "\n",
    "filter_columns & lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2019 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
