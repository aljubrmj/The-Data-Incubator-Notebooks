{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JupyterHub Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter server is running as a [Docker container](https://www.docker.com/resources/what-container) in a [Kubernetes cluster](https://kubernetes.io/).  Docker containers act much like light-weight virtual machines, so you can interact with this much like any other Linux machine.  From the terminal, you can get a Bash shell and thereby execute most any binary.  You even have `sudo` access.\n",
    "\n",
    "However, the container isn't quite a real virtual machine, so there are some differences that you should be aware of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lack of data persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only your home directory (`/home/jovyan`) is stored on a persistent disk.  This means that when your container is restarted, the rest of the file system will be reset to its initial state.  While we will try to leave your container up as much as possible, we may have to restart it occasionally, for a variety of reasons.  While you are welcome to install additional software, any installed outside of your home directory will disappear if your container is restarted.  You may wish to write a script to install this additional software if it is critical to your project.\n",
    "\n",
    "(Incidentally, this may help you if you accidentally mis-configure your container.  Stopping and restarting your Jupyter server from the control panel will reset the container to its initial state.  Please wait for five minutes after stopping the container before restarting it.  Otherwise, your persistent volume may not get hooked up correctly.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conda environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python environment is manged by [Conda](https://conda.io/docs/).  Not only does Conda handle installing packages (with the `conda install` command), it allows you to create independent Python environments each with its own set of packages.\n",
    "\n",
    "The default Python environment has a set of packages that are known to work with the lecture notebooks and miniprojects.  It also lives in `/opt/conda`, and therefore will get reset by container restarts.  However, we have configured Conda such that additional environments will get created in your home directory (specifically, `~/conda-envs`).  Therefore, we recommend that you create another environment to install or upgrade Python packages.\n",
    "\n",
    "To create a new Python 3.6 environment named `capstone-dev`, for example, run\n",
    "```\n",
    "conda create -n capstone-dev python=3.6 ipykernel\n",
    "```\n",
    "(The name is entirely up to you.)  This creates a minimal environment, and installs the IPython kernel, so it can be used in Jupyter notebooks.  Alternatively, you can clone the existing environment into a new environment:\n",
    "```\n",
    "conda create -n capstone-dev --clone data3\n",
    "```\n",
    "\n",
    "Either way, you will have a new environment, but nothing will run in there by default.  In order to use it, you need to activate it:\n",
    "```\n",
    "source activate capstone-dev\n",
    "```\n",
    "Note that the activation operates per shell&mdash;you will need to reactivate this environment if you want it active in another shell.  Conda alters your shell prompt to indicate the current environment, to help you keep track.  Now any `conda` or `pip` commands will operate in this new environment, and any call of `python` will run with the packages installed in it.\n",
    "\n",
    "To use this environment in a Jupyter notebook, we must register the kernel.  From *within the environment*, run\n",
    "```\n",
    "python -m ipykernel install --prefix ~/.local --name capstone-dev --display-name 'Capstone Development'\n",
    "```\n",
    "Both the name and display name are arbitrary, but for your sanity, it is recommended that you use names related to that of the environment.  Now you can create notebooks using this kernel, or switch existing notebooks to use this kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing other ports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While your container has ports just like any other machine, these ports are not accessible to machines outside the cluster, like, for example, your laptop.  This means that if you run a webserver on port 1234, you won't be able to access it at <tt>http://<i>session</i>.tditrain.com:1234</tt>.  (After all, which container should it connect to?)  There are several ways around this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are running a proxy that will connect a specific URL to a port on your container.  That web server you run on port 1234 will be available at <tt>https://<i>session</i>.tditrain.com/user/<i>username</i>/proxy/1234/</tt> (replacing *session* and *username* appropriately, of course).  This doesn't require any additional work on your part, but it comes with two significant caveats.\n",
    "\n",
    "1. This URL is only accessible to you when you are logged in.  This is actually a plus during testing, since you don't want attackers visiting your insecure work-in-progress, but it does mean that you can't show off your work through this URL.\n",
    "\n",
    "2. This means that the URL the browser sees is different from that which your server expects, which is important if you have absolute URLs.  If you reference a stylesheet living at `/css/style.css`, your browser will ask for <tt>https://<i>session</i>.tditrain.com/css/style.css</tt>, but the file will actually be served from <tt>https://<i>session</i>.tditrain.com/user/<i>username</i>/proxy/1234/css/style.css</tt>.  You can avoid this problem by using relative URLs, but that may not always be practical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Port tunneling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of tools that allow port tunneling, but we've had success using [`ngrok`](https://ngrok.com/).  It's installed in your container, but you will need to sign up for a (free) account yourself.  Once you're signed up, you'll need to authenticate (see [step 3 of this page](https://dashboard.ngrok.com/get-started)).\n",
    "\n",
    "At that point, you can tunnel any port through `ngrok`.  To tunnel that website running on port 1234, run\n",
    "```\n",
    "ngrok http 1234\n",
    "```\n",
    "You will then be shown a text UI that includes a URL of the form `http://12345678.ngrok.io`.  Requests sent to that URL will be tunneled through the `ngrok` connection to your container.\n",
    "\n",
    "With the free account, you can only make a single `ngrok` connection at a time; however, that connection can forward up to four ports.  You must use the configuration file at `~/.ngrok2/ngrok.yml` to do this.  To connect the Hadoop UI, at port 8042, as well as your website, add to this configuration file:\n",
    "```\n",
    "tunnels:\n",
    "    website:\n",
    "        proto: http\n",
    "        addr: 1234\n",
    "    hadoop:\n",
    "        proto: http\n",
    "        addr: 8042\n",
    "```\n",
    "and then start both connections from a single command\n",
    "```\n",
    "ngrok start website hadoop\n",
    "```\n",
    "You will get a separate URL for each tunneled port."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up SSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ngrok` also supports raw TCP tunneling.  This can be used to connect to an SSH server running on your container, for example.  There's no need to do this, but some people find it convenient.\n",
    "\n",
    "While the SSH server is installed, it does not start automatically.  You must start it with\n",
    "```\n",
    "sudo service ssh start\n",
    "```\n",
    "The server is configured to only accept public key authentication.  Put your public key in `~/.ssh/authorized_keys`.\n",
    "\n",
    "Now, set up TCP tunneling to port 22.\n",
    "```\n",
    "ngrok tcp 22\n",
    "```\n",
    "You'll get a forwarding address of the form `tcp://0.tcp.ngrok.io:12345`.  On your local machine, you can connect with\n",
    "```\n",
    "ssh jovyan@0.tcp.ngrok.io -p 12345\n",
    "```\n",
    "Note that you're likely to get a different port each time you connect, so you'll likely get a unknown host warning each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid memory contention, each container is subject to a limit of memory usage.  If a process exceeds that limit, it is subject to being killed.  Unfortunately, this limit is not reflected in any of the OS utilities, which show the full memory available to the underlying cluster node.  These limits depend on our cloud server configuration; check with your instructor to find out the limits on your container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Material\n",
    "\n",
    "You might be wondering how to download the material from your servers to your local computer.  There are a few ways to do it!\n",
    "The first way - zip the entire datacourse directory and download with `scp` through `ngrok`\n",
    "1. Install `zip` utility if not installed (`sudo apt install zip` from a terminal)\n",
    "2. zip datacourse directory `zip -r datacourse.zip datacourse/` (you may want to use `-x` flags to exclude things like `.xml.gz`, all the data is public, so you can re-download it from your local machine)\n",
    "3. Create an `ngrok` connection over port 22 (follow instructions above as to how to set this up, make sure to add your ssh public key to authorized keys)\n",
    "4. use `scp` from your local machine to download the zip file, the command will look something like `scp -P 10296 jovyan@0.tcp.ngrok.io:/home/jovyan/datacourse.zip .`\n",
    "\n",
    "If you don't want to zip the entire directory, other options:\n",
    "\n",
    "- Use `rsync`\n",
    "- Push to your own `S3` bucket\n",
    "- Delete all the downloaded data for miniprojects and use the download button in the Jupyter notebook console (this will work up to a few Gb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2019 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
