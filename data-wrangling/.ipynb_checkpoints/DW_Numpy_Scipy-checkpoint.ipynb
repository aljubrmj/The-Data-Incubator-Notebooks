{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy and SciPy\n",
    "<!-- requirement: images/Sparse_vs_Dense_Matrices.svg -->\n",
    "<!-- requirement: images/Numpy_Array_Vs_Python_List.svg -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - What is NumPy?: `ndarray`, `matrix`, and some operations\n",
    " - What is SciPy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the standard \"qualified\" (as) imports\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # makes plots pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've ever used MATLAB, you know that writing out loops to add two vectors / find dot products / multiply two matrices / etc. is possible but _very_ slow.  Instead, you should use \"vectorized\" built-in operations that can do the looping in a faster language or even pick a better algorithm.\n",
    "\n",
    "Python is similar.  _NumPy_ is the package that provides the means to do performant numerical calculations in Python.  If you've converted your problem into linear algebra and matrices, then _NumPy_ will let you write it to run fast.\n",
    "\n",
    "**Why are Python arrays unsuitable for numerical computation?**\n",
    "\n",
    "There are two basic reasons why Python on its own is insufficient here:\n",
    "  - _Data structure._  A Python list is a complicated thing. Just consider something like:\n",
    "```        \n",
    "x = [1, \"23\", BeautifulSoup(urlopen(\"https://www.google.com/#q=4\")), 5]\n",
    "``` \n",
    "    where x[0] and x[3] are numbers (of some sort), x[1] is a string, and x[2] is a complicated object.  If you're familiar with a low-level language like C, just imagine how this must be stored in memory: \n",
    "    \n",
    "    > In the typical Python implementation, this might be stored as a linked list of pointers to \"Python object\" data structures which in turn store what class the object is an instance of, a pointer to a dictionary (i.e. hash table) of instance variables, and a pointer to a dictionary of class variables.  This is reasonable for x[2], but for x[0] and x[3]...\n",
    "    \n",
    "  - _Typing and dispatch._  When we write `x[0] + x[3]`, what happens?  You can overload `+` for all sorts of purposes in Python, and the decision of exactly what `+` means happens at run-time by a dictionary look-up.  If you were term-wise adding two arrays, `x` and `y`, then because arrays can contain elements of different types this has to happen _for each term_.\n",
    "\n",
    "**What NumPy does for us:**\n",
    "\n",
    "The basic thing that NumPy does is avoid these two problems by using ordinary C-style arrays of integers, floating point numbers, etc., along with functions that operate on them intelligently. It also gives us C-style higher dimensional arrays.\n",
    "\n",
    "Note that C-style arrays are good for more than just quickly performing operations through Python; they're also good for talking to existing C and Fortran code. This interoperability explains why NumPy matters to you even if you won't do any matrix computations by hand: many of the libraries that you _will_ want to use will use NumPy arrays under the hood.\n",
    "\n",
    "![NumPy Array vs. Python List](images/Numpy_Array_Vs_Python_List.svg \"Numpy Array vs. Python List\")\n",
    "[comment]: https://docs.google.com/drawings/d/1qsm90ZnesvtRr0_Y_hpJag5nragWv4fmkmfpBZRbxCQ/edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types (the nouns):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `np.ndarray`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a C-style \"n-D\" array.  That is, it is just a big contiguous block of integers (or floats, or... but just one type per array) together with a factorization of its size into \"dimensions\"\n",
    "  \n",
    "  $$       N = n_1 n_2 ... n_d        $$\n",
    "  \n",
    "  In other words the arrays that you might denote [1,2,3,4] and [[1,2],[3,4]] have the same underlying block of values, just with different dimensions: the first one has [4], while the second [2,2].\n",
    "  \n",
    " For an alternate visual: Imagine a grid and numbering it by reading left to right -- next row -- left to right -- next row, etc.   For instance, in C the following bits of code are functionally equivalent\n",
    "  \n",
    "  >        \n",
    "          int chessboard[64];\n",
    "          //Do something\n",
    "          chessboard[8*row + column] += 1;\n",
    "  \n",
    "  and\n",
    "  \n",
    "  >        \n",
    "          int chessboard[8][8];\n",
    "          //Do something\n",
    "          chessboard[row][column] += 1;\n",
    "          \n",
    "  In this case the numbering (i.e. mapping to a single flat list of numbers) goes\n",
    "  >        \n",
    "          0  1  2  3  4  5  6  7\n",
    "          8  9 10 11 ..\n",
    "          16 ..\n",
    "          ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty((2,3))  # allocates memory but does not write to it (dangerous)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.zeros((2,3))  # array of all zeros\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape == Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.ones((2,3))  # array of all ones\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape == Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2 = np.ones_like(Y)  # array of ones with the shape of Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z == Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(Z == Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(Z - Z == Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `np.matrix`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The case of 2D arrays, or \"matrices,\" is given a special wrapper with different operations.  These are slightly different than arrays, which we'll explain later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.matrix(range(5))\n",
    "y = np.arange(5)\n",
    "np.all(x == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x) is type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(x,np.ndarray) # np.matrix is a subclass of np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.matlib  # this import is oddly necessary for matrix code to work\n",
    "matrix_I = np.matlib.identity(3)\n",
    "array_I = np.eye(3)\n",
    "\n",
    "np.all(matrix_I == array_I), type(matrix_I) is type(array_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations (the verbs):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In broad types the things we can do are:\n",
    "  - Create arrays.\n",
    "  - Slicing or reshaping: Taking a sub-block of a block of values.  Both slicing and reshaping are  examples of a \"view\" or a \"shallow copy,\" because they do not actually copy the underlying block of data.\n",
    "  - \"Universal functions\": This is NumPy's name for functions that are applied term-by-term, like the arithmetic operations or `sin`.\n",
    "  - Linear algebra / matrix operations.\n",
    "  - Mathematical convenience functions: FFT, etc.\n",
    "  \n",
    "Here's a table that shows some example syntax:\n",
    "  \n",
    "   Command  |  Explanation\n",
    "   ---------|--------------\n",
    "  `np.array(python_list, dtype='int')` | Convert a Python list to an `np.array`.  The `dtype` can be one of several things, such as 'int64', 'float32', 'float64', etc.\n",
    "  `np.ndarray(shape=[1,2,3], buffer=an_np_array, dtype='int')`  | Makes a higher dimensional array whose underlying block of data is the given `np.array`.\n",
    "  `np.arange(-5,5,1)` | Like Python's range, but slightly faster than `np.array(range(-5,5,1))`.\n",
    "  `+`, `*`, `-`, `/`, `np.sin`, ... | All of the standard numerical and mathematical functions are back.  They always operate term-by-term.  That is, `x+y` is ordinary vector addition but `x*y` is term-wise product (not dot product).\n",
    "   `np.dot(x,y)` or `x.dot(y)` | Inner product (along the last dimension, for n-D arrays).  Note that this includes matrix multiplication for 2-D arrays.\n",
    "   `an_np_array.reshape([1,2,3])`  |  Reshape an `np.array` or `np.ndarray` to one with different shape (but of the same size).\n",
    "   \n",
    "All pretty simple!  Let's do a few quick examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-5, 5, 1)  # NumPy will make intelligent guesses about your intended data type\n",
    "x                        # And will convert between them if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.sin(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.dtype, y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(-5, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(0, 4, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic math operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.dot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(x**2 + y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.outer(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.outer(x, x).dot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How would you multiply two matrices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do basic stats on arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reshape an array, as long as the number of elements remains the same.  Note that the result of a reshape is a view onto the same data.  Changing one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.reshape(2, 5)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[1,1] = 10\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need a deep copy instead of a view, use the .copy() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.reshape(2,5).copy()\n",
    "z[1,1] = 20\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reshape(5, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create an array of arbitrary shape and type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ndarray(shape=(2,3,3), dtype=int, buffer=np.arange(1,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication and Transpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Matrix multiplication, on 2-D arrays, is denoted by `A.dot(B)`.  Transpose is denoted by `A.T`.  Fair enough. \n",
    "2. If `A` is a 1-D array, then we often think of it as a vector.  This will usually give you the right \"linear algebra notation\" answer, e.g. if `M` is a 2-D array of the right size then\n",
    "        A.dot(M)\n",
    "        M.dot(A)\n",
    "   represent the matrix products you think (where `A` is turned into a row or column vector as needed).\n",
    "   \n",
    "   If `A` is a 1-D array, then it is not the case that `A` is always a row (or column) vector -- NumPy makes creative guesses about how to interpret it as a higher dimensional array.  For the matrix outer product $A^T A$ one must use `np.outer(A)` or _explicitly reshape_ `A` as a column vector, i.e. a 2-D array with just one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(x.dot(x.T) == np.outer(x, x)) # x.T doesn't work on 1-D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = x[:, np.newaxis] \n",
    "np.all(v.dot(v.T) == np.outer(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = x.reshape(-1,1)\n",
    "np.all(v.dot(v.T) == np.outer(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of NumPy arrays vs. python lists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's much faster to use NumPy arrays than python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = range(10000)\n",
    "yl = range(10000)\n",
    "xa = np.arange(10000)\n",
    "ya = np.arange(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n3\n",
    "\n",
    "[i + j for i, j in zip(xl, yl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n3\n",
    "\n",
    "xa + ya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array indexing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy provides lots of ways to index into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "y = x[2:5]  # like python list indexing\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the difference?\n",
    "x[2:3], x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select based on a condition\n",
    "x[x % 2 == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy allows you to play fast and loose with indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.empty((3,4))\n",
    "\n",
    "# Constant assigned to entire row\n",
    "for i in range(A.shape[0]):\n",
    "    A[i] = 2. * i\n",
    "    \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass in a list (or `np.array`) of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 2. * np.arange(10)\n",
    "X[range(9,-1,-1)]  # The reverse of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[range(9,-1,-1)] = 3. * np.arange(10)   # Assign to the reverse of this list\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional selection and max / min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.where` construct allows you to take values from one array when a condition is true and the values from another array when they are false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "np.where(x > 5, x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be done manually, by taking advantage of the fact that `True` and `False` behave like `1` and `0` in math statements in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x > 5) * x + 0 * (x <= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.maximum` and `np.minimum` can compare two arrays or an array to a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "y = np.arange(9, -1, -1)\n",
    "print(\"The larger of x and y\")\n",
    "print(np.maximum(x, y))\n",
    "print()\n",
    "print(\"x capped at 5\")\n",
    "print(np.minimum(x, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Inversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While you can invert a 2-D NumPy array using `np.linalg.inv`, it is recommended that you use `np.linalg.solve`, which is much more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3,1], [1,2]])\n",
    "x = np.array([9,8])\n",
    "np.linalg.solve(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can do the [SVD decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition) of a 2-D NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(24).reshape(4,6)\n",
    "U, x, V = np.linalg.svd(A)\n",
    "diag = np.zeros((4,6))\n",
    "diag[range(4), range(4)] = x\n",
    "diff = U.dot(diag).dot(V) - A\n",
    "\n",
    "np.abs(diff).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting NumPy objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save NumPy objects as using `np.save` and `np.load` functions.  You can also save multiple NumPy objects using the `np.savez` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "np.save('/tmp/x.npy', x)\n",
    "del x\n",
    "y = np.load('/tmp/x.npy')\n",
    "np.all(y == np.arange(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises:**\n",
    "Write a one-line function, which when given a random `np.array`:\n",
    "1. returns the range (max - min)\n",
    "1. returns the normalized random variable (subtract the mean and divide by standard deviation)\n",
    "1. returns the value closest to the mean\n",
    "\n",
    "Additional exercises:\n",
    "1. Create a $4 \\times 4$ identity matrix.\n",
    "1. Generate the 2D array\n",
    "```\n",
    "1 2 3\n",
    "4 5 6\n",
    "7 8 9\n",
    "```\n",
    "(without typing it out).\n",
    "1. Generate a random $4 \\times 4 \\times 4$ array of Gaussian distributed numbers.\n",
    "1. Generate `n` evenly spaced intervals between 0 and 1.\n",
    "1. Create an $8 \\times 8$ `np.ndarray` representing a chess board where the red squares are 1 and the white squares are 0.\n",
    "\n",
    "Looking for more?  Check out  the Neophyte, Novice, and  Apprentice levels [here](http://www.loria.fr/~rougier/teaching/numpy.100/).  They get unnecessarily complicated after that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_SciPy_ hooks into efficient implementations (in C and Fortran) of a variety of numerical techniques:\n",
    "\n",
    "- numerical integration \n",
    "- numerical differentiation \n",
    "- optimization and root finding\n",
    "- distributions and special functions\n",
    "- sparse linear algebra  <small>(NumPy is for _dense_ linear algebra)</small>\n",
    "- signal processing\n",
    "- and more\n",
    "\n",
    "The input / output from these commands often involves NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built in tools can do integrals for either functions (in the programming sense) or for discrete data sets, in multiple dimensions, as well as simple ordinary differential equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple integral in 1-D\n",
    "def gauss(x):\n",
    "    return np.exp(-x*x)\n",
    "\n",
    "result = sp.integrate.quad(gauss, -np.inf, np.inf)\n",
    "print(\"Got {:.5f} with error {:.3e}, should have gotten {:.5f}\".format(result[0], result[1], np.sqrt(np.pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volume of a unit sphere intersected with a cylinder of radius 1/2\n",
    "def spherez(x,y):\n",
    "    return np.sqrt(1 - (x**2 + y**2))\n",
    "\n",
    "#order: function, y_lower, y_upper, x_lower, x_upper\n",
    "#x is always integrated first, so it can have y-dependent limits\n",
    "#Result is (answer, error)\n",
    "sp.integrate.dblquad(lambda x, y: 2*spherez(x,y), -1/2, 1/2, \n",
    "                     lambda y: -np.sqrt(1/4 - y**2), lambda y: np.sqrt(1/4 - y**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discrete integral: simpson's rule\n",
    "x = np.linspace(-3,3,40)\n",
    "y = np.exp(-x*x)\n",
    "\n",
    "sp.integrate.simps(y,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy can be used for root finding and optimization.  Among the functions supported are are\n",
    "\n",
    "1. [`root`](http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.optimize.root.html) which finds the roots of arbitrary python functions you pass in\n",
    "1. [`linprog`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html) which solves linear programming problems subject to equality and inequality constraints.\n",
    "1. [`minimize`](http://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.optimize.minimize.html) which minimizes arbitrary functions using various methods like Powell, conjugate gradient, `BFGS`, `LBFGSB`, Newton CG, etc ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root finding of equations or systems of equations is done, unsurprisingly, with `root`.  There are many methods available, for modest dimensions the default (`hybr`) and Levenberg-Marquardt (`lm`) are normally used.  As the number of dimensions grows large the computation of the Jacobian becomes a problem, and more approximate methods like `krylov` and `broyden2` are available.  They are selected between using the `method` keyword.\n",
    "\n",
    "If we have it available, we can also explicitly compute the derivative to aid the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A very simple case to get the square root of 2\n",
    "function = lambda x: x**2 - 2\n",
    "\n",
    "initial_guess = 4\n",
    "result = sp.optimize.root(function, initial_guess)\n",
    "\n",
    "print(\"Sqrt of 2: {}\".format(result.x))\n",
    "\n",
    "x = np.arange(-1., 2., .1-1e-9)\n",
    "y = function(x)\n",
    "plt.plot(x, y)\n",
    "plt.plot([result['x']], result['fun'], 'o', markersize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try a more complicated case, the intersection of two circles.  Here we will also compute the derivative (in this case the Jacobian).  While this is optional, it can enhance performance.  We can tell the `root` method to expect this Jacobian by setting the keyword argument `jac=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigfun(xx):\n",
    "    #x^2 + y^2 - 1 = 0\n",
    "    #(x-1)^2 + (y-1)^2 - 1.5^2 = 0\n",
    "    #Derivatives are a 2x2 Jacobian\n",
    "    #[2x, 2y]\n",
    "    #[2x-2, 2y-2]\n",
    "    x = xx[0]\n",
    "    y = xx[1]\n",
    "    f = [x*x + y*y - 1, (x-1)*(x-1) + (y-1)*(y-1) - 1.5*1.5]\n",
    "    df = [[2*x, 2*y], [2*x - 2, 2*y - 2]]\n",
    "    return f, df\n",
    "\n",
    "#Two calls, one for each intersection\n",
    "result1 = sp.optimize.root(bigfun, [0, 0.75], jac=True, method='lm')\n",
    "result2 = sp.optimize.root(bigfun, [1, 0], jac=True)\n",
    "\n",
    "#plot circles and found point\n",
    "t = np.linspace(0,2*np.pi,100)\n",
    "x = np.cos(t)\n",
    "y = np.sin(t)\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "plt.plot(x,y, 1.5*x+1,1.5*y+1)\n",
    "plt.plot(*result1['x'], 'o', markersize=10)\n",
    "plt.plot(*result2['x'], 'o', markersize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimizing a function of one or many variables is a common task, and often occurs in the context of curve fitting.  SciPy has a `minimize` function for the general case, and a `least_squares`  and `curve_fit` that are more optimized for their respective types of problems.  Both have many `method` options for different cases and types of constraints, but each method has its own way of taking in constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple, unconstrained mimization\n",
    "function = lambda x: x**4 - 2*x**3 - 2*(x-1)**2 + 1\n",
    "guess = 0.5\n",
    "result = sp.optimize.minimize(function, guess)\n",
    "\n",
    "x = np.arange(-2, 3, .1-1e-9)\n",
    "y = function(x)\n",
    "plt.plot(x, y)\n",
    "plt.plot([result['x']], result['fun'], 'o', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same problem, only positive solutions\n",
    "result = sp.optimize.minimize(function, 0.5, bounds=[(0,np.inf)])\n",
    "\n",
    "x = np.arange(-2, 3, .1-1e-9)\n",
    "y = function(x)\n",
    "plt.plot(x, y)\n",
    "plt.plot([result['x']], result['fun'], 'o', markersize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it settles at zero, which is the \"minimum\" closest to our starting point.  Maybe not what we wanted here, so we'd have been better served by altering our starting point.\n",
    "\n",
    "Let's look at a constrained problem, with non-linear constraints.  To keep it simple, let's minimize the cost of building a fence, where the \"vertical\" and \"horizontal\" sides cost different amounts (say 4/unit and 7/unit), but we want to enclose at least 100 units of area.\n",
    "\n",
    "Our constraint is \"greater than 100\", if it was \"exactly 100\" we'd use type `eq`.  Note our constraints are always $f(x) >= 0$, so we rewrite our constraint from $x*y >= 100$ to $x*y - 100 >= 0$.  Also note, we can have both `ineq` and `eq` constraints, we then give `constraints=[eq, ineq]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One option for constrained fits: boundaries on parameters\n",
    "#We'll use Sequential Least Squares\n",
    "\n",
    "def cost(x):\n",
    "    return 7*x[0] + 4*x[1]\n",
    "\n",
    "def area(x):\n",
    "    return x[0]*x[1]\n",
    "\n",
    "ineq_cons = {'type': 'ineq', \n",
    "             'fun': lambda x: [area(x) - 100], #Multiple constraints are just more list entries\n",
    "             'jac': lambda x: [[x[1], x[0]]]} #we must explicitly provide the derivates of the constraints\n",
    "\n",
    "results = sp.optimize.minimize(cost, [1,1], method='SLSQP', constraints=ineq_cons, bounds=[(0,np.inf),(0,np.inf)])\n",
    "print('x = {:.3f}, y = {:.3f}, giving cost = {:.3f} and area = {:.3f}'\n",
    "      .format(results.x[0], results.x[1], cost(results.x), area(results.x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy and SciPy can generate random numbers using functions in the `np.random` namespace.  NumPy arrays also have some built-in statistical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(100)  # random standard normal of size 100\n",
    "x.mean(), x.std(), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy also also supports more complex statistical functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(x, 10), np.median(x), np.percentile(x, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy has strong support for data from different distributions.  Each distribution is represented by a class\n",
    "\n",
    "It also supports various continuous and discontinuous distributions, such as\n",
    "- [Bernoulli](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bernoulli.html#scipy.stats.bernoulli)\n",
    "- [Beta](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html#scipy.stats.beta)\n",
    "- [Binomial](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html#scipy.stats.binom)\n",
    "- [Cauchy](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.cauchy.html#scipy.stats.cauchy)\n",
    "- [Chi-Squared](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html#scipy.stats.chi2)\n",
    "- [Exponential](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html#scipy.stats.expon)\n",
    "- [Gamma](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html#scipy.stats.gamma)\n",
    "- [Normal](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm)\n",
    "- [Poisson](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html#scipy.stats.poisson)\n",
    "- etc ...\n",
    "\n",
    "which supports several methods, including\n",
    "\n",
    "- [`rvs`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.rvs.html#scipy.stats.rv_continuous.rvs): generating random variates\n",
    "- [`pdf`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.pdf.html#scipy.stats.rv_continuous.pdf):  returning the PDF of a distribution\n",
    "- [`logpdf`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.logpdf.html#scipy.stats.rv_continuous.logpdf): returning the log PDF of a distribution\n",
    "- [`cdf`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.cdf.html#scipy.stats.rv_continuous.cdf): returning the CDF of a distribution\n",
    "- [`mean`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.logpdf.html#scipy.stats.rv_continuous.mean): returns the mean\n",
    "- [`var`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.logpdf.html#scipy.stats.rv_continuous.var): returns the variance\n",
    "- [`std`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.logpdf.html#scipy.stats.rv_continuous.std): returns the standard deviation\n",
    "- [`moment`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.moment.html#scipy.stats.rv_continuous.moment): returning the n-th moment\n",
    "- [`stats`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.stats.html#scipy.stats.rv_continuous.stats): returning various statistics\n",
    "- etc ...\n",
    "\n",
    "which can be instantiated with standardized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cauchies = [(loc, sp.stats.cauchy(loc=loc, scale=1.)) for loc in (-1, 0, 1)]\n",
    "x = np.arange(-3., 3., .05-1e-9)\n",
    "for loc, cauchy in cauchies:\n",
    "    plt.plot(x, cauchy.pdf(x), label=\"loc=%+d\" % loc)\n",
    "plt.legend()\n",
    "plt.title(\"Cauchy PDFs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [(a, sp.stats.gamma(a=a)) for a in range(1,8)]\n",
    "x = np.arange(0., 10., .1-1e-9)\n",
    "for a, gamma in gammas:\n",
    "    plt.plot(x, gamma.cdf(x), label=\"a=%d\" % a)\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Gamma CDFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse matrices are great for matrices that are mostly zeros.  There are many formats, which each have different advantages:\n",
    "- [`COO`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html#scipy.sparse.coo_matrix): this is the easiest class to construct, but bad at computation\n",
    "- [`CSC`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html#scipy.sparse.csc_matrix): also called column-based, these are good for column-slicing but poor at row slicing.\n",
    "- [`CSR`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html#scipy.sparse.csc_matrix): also called row-based, these are good for row-slicing but poor at column slicing.\n",
    "- [`DIA`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.dia_matrix.html#scipy.sparse.dia_matrix): also called diagonal storage, these are great for diagonal matrices.\n",
    "\n",
    "![Sparse vs. dense matrices](images/Sparse_vs_Dense_Matrices.svg \"Sprase Vs. Dense Matrices\")\n",
    "[comment]: https://docs.google.com/drawings/d/1s9JQVUPO4RJnAFdcWFG-Xxz_-m0oJv7yvvK3EE00SAM/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_matrix(n):\n",
    "    matrix = sp.sparse.dia_matrix(((np.ones(n), np.ones(n)), (1,1-n)), shape=(n,n))\n",
    "    return matrix\n",
    "\n",
    "print(shift_matrix(4))\n",
    "shift_matrix(4).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that dense matrix multiplication is slower than sparse matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "T = 50\n",
    "m_dense = shift_matrix(N).todense()\n",
    "m_sparse = shift_matrix(N).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "v0 = np.arange(N).reshape((N,1))\n",
    "for _ in range(T):\n",
    "    v0 = m_dense * v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "v0 = np.arange(N).reshape((N,1))\n",
    "for _ in range(T):\n",
    "    v0 = m_sparse * v0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signal processing package in SciPy has methods relating to B-splines, convolution, and filter design.  We'll just look at convolutions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The same flag makes the output the same length as the first argument\n",
    "#Without it, you get the full convolution of size len(x) + len(k) - 1\n",
    "import scipy.signal\n",
    "x = [0,0.1,1,1,1,1,0,0,2,3,4,3,2,0,0]\n",
    "k = [1/3,1/3,1/3]\n",
    "conv = sp.signal.convolve(x,k)\n",
    "print(conv)\n",
    "print(\"Length of x = {}, full convolution length = {}\".format(len(x), len(conv)))\n",
    "\n",
    "conv = sp.signal.convolve(x,k,'same')\n",
    "plt.plot(x,'o',color='blue')\n",
    "plt.plot(conv,'o',color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some simple data\n",
    "x = np.linspace(-5,5,100)\n",
    "y = np.sin(x) + np.random.normal(0,0.1,size=(100))\n",
    "plt.plot(x,y,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "little = np.linspace(-1.5,1.5,10)\n",
    "filt = np.exp(-little**2)\n",
    "filt = filt / sum(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the same three element flat kernel as before\n",
    "#it still picks up much of the noise\n",
    "k = np.array([1,1,1]) / 3\n",
    "conv = sp.signal.convolve(y,k,'same')\n",
    "plt.plot(x,y,'o')\n",
    "plt.plot(x,conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using a larger gaussian kernel\n",
    "#Note the fall-off on the ends from the zero padding\n",
    "filt_x = np.linspace(-1.5,1.5,10)\n",
    "filt = np.exp(-little**2)\n",
    "filt = filt / sum(filt)\n",
    "\n",
    "conv = sp.signal.convolve(y,filt,'same')\n",
    "plt.plot(x,y,'o')\n",
    "plt.plot(x,conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A 2-D edge detector\n",
    "img = np.zeros((100,100))\n",
    "img[20:40,30:50] = 0.4\n",
    "img[40:80,20:80] = 0.4\n",
    "img[50:70,10:90] = 1\n",
    "plt.grid(False)\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "filt = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]]) / 8\n",
    "filtered = sp.signal.convolve(img,filt,'same')\n",
    "plt.grid(False)\n",
    "plt.imshow(abs(filtered),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extremely important tool, FFTs are implemented in a very straightforward manner.  These are discrete FFTs, so the assumption built-in is that the data is equally spaced and we can ignore that spacing, so they only take the \"y\" values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The basic fft returns complex results, of course\n",
    "x = np.linspace(-5,5,1000)\n",
    "y = np.sin(x*20) + 0.2*np.cos(x*100) + np.random.normal(0,0.1,size=(1000))\n",
    "fd_complex = sp.fftpack.fft(y)\n",
    "plt.plot(abs(fd_complex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfft takes the \"real\" FFT\n",
    "fd_real = sp.fftpack.rfft(y)\n",
    "plt.plot(fd_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And we invert with the appropriate ifft or irfft (for complex and real, respectively)\n",
    "#For the complex case, we'll need to drop the rounding-error complex components\n",
    "reconstructed = sp.fftpack.ifft(fd_complex)\n",
    "plt.plot(np.real(reconstructed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = sp.fftpack.irfft(fd_real)\n",
    "plt.plot(reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises:**\n",
    "1. Linear regression is a *Least Squares* model because it minimizes the potential function\n",
    "$$ \\sum_i (y_i - (b_0 + b_1 X_{1i} + \\cdots b_p X_{pi}))^2 $$\n",
    "Use the matrix operations provided by NumPy and the optimization routines provided by SciPy to write your own least-squares routine.  Check the result using `numpy.linalg.lstsq`.\n",
    "\n",
    "1. Generate some noisy data fitting the model $y = e^{-a x} + b + \\epsilon$ where $\\epsilon$ is random Gaussian noise and $a>0$ and $b$ are real numbers.  Use `scipy.optimize.curve_fit` to get the data to the parametric form $f(x) = e^{-a x} + b$ and check that you can recover the values of $a$ and $b$.\n",
    "\n",
    "1. Generate an `np.array` of normally distributed samples and apply the normal CDF to them pointwise (`scipy.stats.norm.cdf`).  Generate the histogram.  Can you figure out what distribution this approaches as the number of samples increases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exit Tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What do we mean by \"efficient\" implementations of mathematical operations?\n",
    "1. Identify the aspects of Python responsible for its relatively slow performance. What benefits do we get in return?\n",
    "1. Libraries like NumPy and SciPy offer substantial benefits. What are some of their drawbacks?\n",
    "1. (*extension*) How do you decide when to import functionality and when to implement it yourself?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2015 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
